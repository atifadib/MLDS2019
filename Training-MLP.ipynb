{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_excel('normed_train_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 13)                91        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_to_id = {}\n",
    "for country in train_data['Country Code']:\n",
    "    if country in country_to_id.keys():\n",
    "        pass\n",
    "    else:\n",
    "        if len(country_to_id)==0:\n",
    "            country_to_id[country]=0\n",
    "        else:\n",
    "            country_to_id[country]=max(country_to_id.values())+1\n",
    "def get(c):\n",
    "    return country_to_id[c]\n",
    "train_data['norm_id'] = train_data['Country Code'].apply(get)\n",
    "X = train_data[['norm_id','norm_year','norm_gdp','norm_trade','norm_inflation','norm_exports']].values\n",
    "y = train_data[['Balance']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3816/3816 [==============================] - 1s 264us/step - loss: 1316980812598493315072.0000\n",
      "Epoch 2/100\n",
      "3816/3816 [==============================] - 1s 230us/step - loss: 1316980789731903930368.0000\n",
      "Epoch 3/100\n",
      "3816/3816 [==============================] - 1s 174us/step - loss: 1316980816567900831744.0000\n",
      "Epoch 4/100\n",
      "3816/3816 [==============================] - 1s 179us/step - loss: 1316980812036679401472.0000\n",
      "Epoch 5/100\n",
      "3816/3816 [==============================] - 1s 181us/step - loss: 1316980807510633742336.0000\n",
      "Epoch 6/100\n",
      "3816/3816 [==============================] - 1s 267us/step - loss: 1316980803964927475712.0000\n",
      "Epoch 7/100\n",
      "3816/3816 [==============================] - 1s 189us/step - loss: 1316980799716236197888.0000\n",
      "Epoch 8/100\n",
      "3816/3816 [==============================] - 1s 178us/step - loss: 1316980822023409762304.0000\n",
      "Epoch 9/100\n",
      "3816/3816 [==============================] - 1s 181us/step - loss: 1316980827553028636672.0000\n",
      "Epoch 10/100\n",
      "3816/3816 [==============================] - 1s 179us/step - loss: 1316980784655332016128.0000\n",
      "Epoch 11/100\n",
      "3816/3816 [==============================] - 1s 183us/step - loss: 1316980799872912588800.0000\n",
      "Epoch 12/100\n",
      "3816/3816 [==============================] - 1s 289us/step - loss: 1316980831595789549568.0000\n",
      "Epoch 13/100\n",
      "3816/3816 [==============================] - 1s 193us/step - loss: 1316980800036228038656.0000\n",
      "Epoch 14/100\n",
      "3816/3816 [==============================] - 1s 280us/step - loss: 1316980818841819152384.0000\n",
      "Epoch 15/100\n",
      "3816/3816 [==============================] - 1s 213us/step - loss: 1316980792400154198016.0000\n",
      "Epoch 16/100\n",
      "3816/3816 [==============================] - 1s 183us/step - loss: 1316980833339180056576.0000\n",
      "Epoch 17/100\n",
      "3816/3816 [==============================] - 1s 275us/step - loss: 1316980814401746763776.0000\n",
      "Epoch 18/100\n",
      "3816/3816 [==============================] - 1s 336us/step - loss: 1316980821778961530880.0000\n",
      "Epoch 19/100\n",
      "3816/3816 [==============================] - 1s 185us/step - loss: 1316980797202644598784.0000\n",
      "Epoch 20/100\n",
      "3816/3816 [==============================] - 1s 177us/step - loss: 1316980814273818918912.0000\n",
      "Epoch 21/100\n",
      "3816/3816 [==============================] - 1s 180us/step - loss: 1316980814566024544256.0000\n",
      "Epoch 22/100\n",
      "3816/3816 [==============================] - 1s 175us/step - loss: 1316980796398070136832.0000\n",
      "Epoch 23/100\n",
      "3816/3816 [==============================] - 1s 179us/step - loss: 1316980804791718641664.0000\n",
      "Epoch 24/100\n",
      "3816/3816 [==============================] - 1s 178us/step - loss: 1316980808077054836736.0000\n",
      "Epoch 25/100\n",
      "3816/3816 [==============================] - 1s 178us/step - loss: 1316980812273508941824.0000\n",
      "Epoch 26/100\n",
      "3816/3816 [==============================] - 1s 177us/step - loss: 1316980830085327093760.0000\n",
      "Epoch 27/100\n",
      "3816/3816 [==============================] - 1s 177us/step - loss: 1316980826764947488768.0000\n",
      "Epoch 28/100\n",
      "3816/3816 [==============================] - 1s 177us/step - loss: 1316980812594623021056.0000\n",
      "Epoch 29/100\n",
      "3816/3816 [==============================] - 1s 182us/step - loss: 1316980793539606085632.0000\n",
      "Epoch 30/100\n",
      "3816/3816 [==============================] - 1s 183us/step - loss: 1316980802278159286272.0000\n",
      "Epoch 31/100\n",
      "3816/3816 [==============================] - 1s 182us/step - loss: 1316980809322077618176.0000\n",
      "Epoch 32/100\n",
      "3816/3816 [==============================] - 1s 179us/step - loss: 1316980779207986249728.0000\n",
      "Epoch 33/100\n",
      "3816/3816 [==============================] - 1s 179us/step - loss: 1316980813512343027712.0000\n",
      "Epoch 34/100\n",
      "3816/3816 [==============================] - 1s 180us/step - loss: 1316980824999319306240.0000\n",
      "Epoch 35/100\n",
      "3816/3816 [==============================] - 1s 181us/step - loss: 1316980802646805839872.0000\n",
      "Epoch 36/100\n",
      "3816/3816 [==============================] - 1s 178us/step - loss: 1316980822530726297600.0000\n",
      "Epoch 37/100\n",
      "3816/3816 [==============================] - 1s 186us/step - loss: 1316980845268559200256.0000\n",
      "Epoch 38/100\n",
      "3816/3816 [==============================] - 1s 182us/step - loss: 1316980813239126327296.0000\n",
      "Epoch 39/100\n",
      "3816/3816 [==============================] - 1s 180us/step - loss: 1316980821179809923072.0000\n",
      "Epoch 40/100\n",
      "3816/3816 [==============================] - 1s 183us/step - loss: 1316980817060458921984.0000\n",
      "Epoch 41/100\n",
      "3816/3816 [==============================] - 1s 180us/step - loss: 1316980804402480152576.0000\n",
      "Epoch 42/100\n",
      "3816/3816 [==============================] - 1s 182us/step - loss: 1316980834813315645440.0000\n",
      "Epoch 43/100\n",
      "3816/3816 [==============================] - 1s 179us/step - loss: 1316980803785456877568.0000\n",
      "Epoch 44/100\n",
      "3816/3816 [==============================] - 1s 181us/step - loss: 1316980790986381197312.0000\n",
      "Epoch 45/100\n",
      "3816/3816 [==============================] - 1s 184us/step - loss: 1316980799163410677760.0000\n",
      "Epoch 46/100\n",
      "3816/3816 [==============================] - 1s 182us/step - loss: 1316980801502561697792.0000\n",
      "Epoch 47/100\n",
      "3816/3816 [==============================] - 1s 182us/step - loss: 1316980826955549507584.0000\n",
      "Epoch 48/100\n",
      "3816/3816 [==============================] - 1s 180us/step - loss: 1316980786538703224832.0000\n",
      "Epoch 49/100\n",
      "3816/3816 [==============================] - 1s 180us/step - loss: 1316980790182751502336.0000\n",
      "Epoch 50/100\n",
      "3816/3816 [==============================] - 1s 177us/step - loss: 1316980788856899239936.0000\n",
      "Epoch 51/100\n",
      "3816/3816 [==============================] - 1s 181us/step - loss: 1316980799551269240832.0000\n",
      "Epoch 52/100\n",
      "3816/3816 [==============================] - 1s 181us/step - loss: 1316980823012467802112.0000\n",
      "Epoch 53/100\n",
      "3816/3816 [==============================] - 1s 183us/step - loss: 1316980814830676475904.0000\n",
      "Epoch 54/100\n",
      "3816/3816 [==============================] - 1s 184us/step - loss: 1316980809865460449280.0000\n",
      "Epoch 55/100\n",
      "3816/3816 [==============================] - 1s 180us/step - loss: 1316980822348051775488.0000\n",
      "Epoch 56/100\n",
      "3816/3816 [==============================] - 1s 183us/step - loss: 1316980816826876297216.0000\n",
      "Epoch 57/100\n",
      "3816/3816 [==============================] - 1s 181us/step - loss: 1316980830623324962816.0000\n",
      "Epoch 58/100\n",
      "3816/3816 [==============================] - 1s 182us/step - loss: 1316980827211468374016.0000\n",
      "Epoch 59/100\n",
      "3816/3816 [==============================] - 1s 183us/step - loss: 1316980833590923231232.0000\n",
      "Epoch 60/100\n",
      "3816/3816 [==============================] - 1s 184us/step - loss: 1316980815446026485760.0000\n",
      "Epoch 61/100\n",
      "3816/3816 [==============================] - 1s 185us/step - loss: 1316980811761538826240.0000\n",
      "Epoch 62/100\n",
      "3816/3816 [==============================] - 1s 184us/step - loss: 1316980787996715384832.0000\n",
      "Epoch 63/100\n",
      "3816/3816 [==============================] - 1s 181us/step - loss: 1316980787650699722752.0000\n",
      "Epoch 64/100\n",
      "3816/3816 [==============================] - 1s 184us/step - loss: 1316980829217729282048.0000\n",
      "Epoch 65/100\n",
      "3816/3816 [==============================] - 1s 185us/step - loss: 1316980798535287439360.0000\n",
      "Epoch 66/100\n",
      "3816/3816 [==============================] - 1s 185us/step - loss: 1316980829432177754112.0000\n",
      "Epoch 67/100\n",
      "3816/3816 [==============================] - 1s 185us/step - loss: 1316980799950316109824.0000\n",
      "Epoch 68/100\n",
      "3816/3816 [==============================] - 1s 182us/step - loss: 1316980821924306223104.0000\n",
      "Epoch 69/100\n",
      "3816/3816 [==============================] - 1s 189us/step - loss: 1316980822152411086848.0000\n",
      "Epoch 70/100\n",
      "3816/3816 [==============================] - 1s 184us/step - loss: 1316980784649761456128.0000\n",
      "Epoch 71/100\n",
      "3816/3816 [==============================] - 1s 183us/step - loss: 1316980824418500739072.0000\n",
      "Epoch 72/100\n",
      "3816/3816 [==============================] - 1s 194us/step - loss: 1316980808802821734400.0000\n",
      "Epoch 73/100\n",
      "3816/3816 [==============================] - 1s 194us/step - loss: 1316980782850925658112.0000\n",
      "Epoch 74/100\n",
      "3816/3816 [==============================] - 1s 196us/step - loss: 1316980789844397522944.0000\n",
      "Epoch 75/100\n",
      "3816/3816 [==============================] - 1s 194us/step - loss: 1316980804570923925504.0000\n",
      "Epoch 76/100\n",
      "3816/3816 [==============================] - 1s 196us/step - loss: 1316980815140058038272.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "3816/3816 [==============================] - 1s 181us/step - loss: 1316980817646425997312.0000\n",
      "Epoch 78/100\n",
      "3816/3816 [==============================] - 1s 181us/step - loss: 1316980804046970421248.0000\n",
      "Epoch 79/100\n",
      "3816/3816 [==============================] - 1s 183us/step - loss: 1316980800414706040832.0000\n",
      "Epoch 80/100\n",
      "3816/3816 [==============================] - 1s 176us/step - loss: 1316980778521213272064.0000\n",
      "Epoch 81/100\n",
      "3816/3816 [==============================] - 1s 175us/step - loss: 1316980813635968565248.0000\n",
      "Epoch 82/100\n",
      "3816/3816 [==============================] - 1s 167us/step - loss: 1316980823657463676928.0000\n",
      "Epoch 83/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1316980801011100155904.0000\n",
      "Epoch 84/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1316980815332237377536.0000\n",
      "Epoch 85/100\n",
      "3816/3816 [==============================] - 1s 167us/step - loss: 1316980811808564051968.0000\n",
      "Epoch 86/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1316980798606848294912.0000\n",
      "Epoch 87/100\n",
      "3816/3816 [==============================] - 1s 175us/step - loss: 1316980813029407195136.0000\n",
      "Epoch 88/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1316980798039859396608.0000\n",
      "Epoch 89/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1316980816044392185856.0000\n",
      "Epoch 90/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1316980820629450915840.0000\n",
      "Epoch 91/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1316980802790889095168.0000\n",
      "Epoch 92/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1316980791507612336128.0000\n",
      "Epoch 93/100\n",
      "3816/3816 [==============================] - 1s 176us/step - loss: 1316980795982758543360.0000\n",
      "Epoch 94/100\n",
      "3816/3816 [==============================] - 1s 168us/step - loss: 1316980785141423800320.0000\n",
      "Epoch 95/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1316980776887422812160.0000\n",
      "Epoch 96/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1316980818303928762368.0000\n",
      "Epoch 97/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1316980796409112166400.0000\n",
      "Epoch 98/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1316980787637595144192.0000\n",
      "Epoch 99/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1316980803325349593088.0000\n",
      "Epoch 100/100\n",
      "3816/3816 [==============================] - 1s 174us/step - loss: 1316980822635334336512.0000\n",
      "424/424 [==============================] - 0s 245us/step\n",
      "Epoch 1/100\n",
      "3816/3816 [==============================] - 1s 235us/step - loss: 1398211560965325717504.0000\n",
      "Epoch 2/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1398211627091205554176.0000\n",
      "Epoch 3/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1398211564579889872896.0000\n",
      "Epoch 4/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1398211581418485055488.0000\n",
      "Epoch 5/100\n",
      "3816/3816 [==============================] - 1s 174us/step - loss: 1398211574556404219904.0000\n",
      "Epoch 6/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1398211599548822847488.0000\n",
      "Epoch 7/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1398211582551083712512.0000\n",
      "Epoch 8/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1398211595773615276032.0000\n",
      "Epoch 9/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1398211578201780256768.0000\n",
      "Epoch 10/100\n",
      "3816/3816 [==============================] - 1s 178us/step - loss: 1398211618920025030656.0000\n",
      "Epoch 11/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1398211602784766918656.0000\n",
      "Epoch 12/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1398211593143182950400.0000\n",
      "Epoch 13/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1398211574530144206848.0000\n",
      "Epoch 14/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1398211572738932867072.0000\n",
      "Epoch 15/100\n",
      "3816/3816 [==============================] - 1s 176us/step - loss: 1398211577060449058816.0000\n",
      "Epoch 16/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1398211600738561556480.0000\n",
      "Epoch 17/100\n",
      "3816/3816 [==============================] - 1s 168us/step - loss: 1398211608234403299328.0000\n",
      "Epoch 18/100\n",
      "3816/3816 [==============================] - 1s 168us/step - loss: 1398211578767553855488.0000\n",
      "Epoch 19/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1398211570653622697984.0000\n",
      "Epoch 20/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1398211589554618761216.0000\n",
      "Epoch 21/100\n",
      "3816/3816 [==============================] - 1s 175us/step - loss: 1398211584854405414912.0000\n",
      "Epoch 22/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1398211613363980730368.0000\n",
      "Epoch 23/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1398211565083808759808.0000\n",
      "Epoch 24/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1398211579596620693504.0000\n",
      "Epoch 25/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1398211581541849497600.0000\n",
      "Epoch 26/100\n",
      "3816/3816 [==============================] - 1s 175us/step - loss: 1398211591902630248448.0000\n",
      "Epoch 27/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1398211573988403445760.0000\n",
      "Epoch 28/100\n",
      "3816/3816 [==============================] - 1s 175us/step - loss: 1398211593259370676224.0000\n",
      "Epoch 29/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1398211588207252602880.0000\n",
      "Epoch 30/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1398211592117760819200.0000\n",
      "Epoch 31/100\n",
      "3816/3816 [==============================] - 1s 176us/step - loss: 1398211587229426909184.0000\n",
      "Epoch 32/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1398211574974862065664.0000\n",
      "Epoch 33/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1398211615893540831232.0000\n",
      "Epoch 34/100\n",
      "3816/3816 [==============================] - 1s 181us/step - loss: 1398211592945997447168.0000\n",
      "Epoch 35/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1398211583452090728448.0000\n",
      "Epoch 36/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1398211564478202118144.0000\n",
      "Epoch 37/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1398211605696971800576.0000\n",
      "Epoch 38/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1398211600431464579072.0000\n",
      "Epoch 39/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1398211592856177737728.0000\n",
      "Epoch 40/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1398211584001815347200.0000\n",
      "Epoch 41/100\n",
      "3816/3816 [==============================] - 1s 177us/step - loss: 1398211600193294958592.0000\n",
      "Epoch 42/100\n",
      "3816/3816 [==============================] - 1s 176us/step - loss: 1398211595249051762688.0000\n",
      "Epoch 43/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1398211579662444003328.0000\n",
      "Epoch 44/100\n",
      "3816/3816 [==============================] - 1s 177us/step - loss: 1398211564197099864064.0000\n",
      "Epoch 45/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1398211579077074878464.0000\n",
      "Epoch 46/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1398211575715661873152.0000\n",
      "Epoch 47/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1398211572094800232448.0000\n",
      "Epoch 48/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1398211576554191585280.0000\n",
      "Epoch 49/100\n",
      "3816/3816 [==============================] - 1s 177us/step - loss: 1398211576019905413120.0000\n",
      "Epoch 50/100\n",
      "3816/3816 [==============================] - 1s 179us/step - loss: 1398211567042142404608.0000\n",
      "Epoch 51/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1398211611105481457664.0000\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3816/3816 [==============================] - 1s 174us/step - loss: 1398211600059248672768.0000\n",
      "Epoch 53/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1398211567391898599424.0000\n",
      "Epoch 54/100\n",
      "3816/3816 [==============================] - 1s 168us/step - loss: 1398211592281906216960.0000\n",
      "Epoch 55/100\n",
      "3816/3816 [==============================] - 1s 167us/step - loss: 1398211603892077068288.0000\n",
      "Epoch 56/100\n",
      "3816/3816 [==============================] - 1s 167us/step - loss: 1398211608799533334528.0000\n",
      "Epoch 57/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1398211597556746027008.0000\n",
      "Epoch 58/100\n",
      "3816/3816 [==============================] - 1s 167us/step - loss: 1398211549224296513536.0000\n",
      "Epoch 59/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1398211566685673488384.0000\n",
      "Epoch 60/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1398211600791824236544.0000\n",
      "Epoch 61/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1398211571076497670144.0000\n",
      "Epoch 62/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1398211591121608638464.0000\n",
      "Epoch 63/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1398211603494824050688.0000\n",
      "Epoch 64/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1398211569452157501440.0000\n",
      "Epoch 65/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1398211585797131337728.0000\n",
      "Epoch 66/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1398211583993004687360.0000\n",
      "Epoch 67/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1398211586485545861120.0000\n",
      "Epoch 68/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1398211588807518060544.0000\n",
      "Epoch 69/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1398211563060217249792.0000\n",
      "Epoch 70/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1398211574581598093312.0000\n",
      "Epoch 71/100\n",
      "3816/3816 [==============================] - 1s 186us/step - loss: 1398211591115251646464.0000\n",
      "Epoch 72/100\n",
      "3816/3816 [==============================] - 1s 183us/step - loss: 1398211592792866816000.0000\n",
      "Epoch 73/100\n",
      "3816/3816 [==============================] - 1s 177us/step - loss: 1398211564905603268608.0000\n",
      "Epoch 74/100\n",
      "3816/3816 [==============================] - 1s 184us/step - loss: 1398211569557887254528.0000\n",
      "Epoch 75/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1398211552741667897344.0000\n",
      "Epoch 76/100\n",
      "3816/3816 [==============================] - 1s 186us/step - loss: 1398211598178653831168.0000\n",
      "Epoch 77/100\n",
      "3816/3816 [==============================] - 1s 193us/step - loss: 1398211577685450424320.0000\n",
      "Epoch 78/100\n",
      "3816/3816 [==============================] - 1s 203us/step - loss: 1398211568128863764480.0000\n",
      "Epoch 79/100\n",
      "3816/3816 [==============================] - 1s 212us/step - loss: 1398211587579668070400.0000\n",
      "Epoch 80/100\n",
      "3816/3816 [==============================] - 1s 221us/step - loss: 1398211570774021242880.0000\n",
      "Epoch 81/100\n",
      "3816/3816 [==============================] - 1s 308us/step - loss: 1398211606859296538624.0000\n",
      "Epoch 82/100\n",
      "3816/3816 [==============================] - 1s 209us/step - loss: 1398211596803388735488.0000\n",
      "Epoch 83/100\n",
      "3816/3816 [==============================] - 1s 255us/step - loss: 1398211582508283461632.0000\n",
      "Epoch 84/100\n",
      "3816/3816 [==============================] - 1s 196us/step - loss: 1398211587994963673088.0000\n",
      "Epoch 85/100\n",
      "3816/3816 [==============================] - 1s 209us/step - loss: 1398211555878367395840.0000\n",
      "Epoch 86/100\n",
      "3816/3816 [==============================] - 1s 236us/step - loss: 1398211571938927837184.0000\n",
      "Epoch 87/100\n",
      "3816/3816 [==============================] - 1s 274us/step - loss: 1398211569843795656704.0000\n",
      "Epoch 88/100\n",
      "3816/3816 [==============================] - 1s 229us/step - loss: 1398211590466254667776.0000\n",
      "Epoch 89/100\n",
      "3816/3816 [==============================] - 1s 211us/step - loss: 1398211588617625403392.0000\n",
      "Epoch 90/100\n",
      "3816/3816 [==============================] - 1s 227us/step - loss: 1398211566203434958848.0000\n",
      "Epoch 91/100\n",
      "3816/3816 [==============================] - 1s 206us/step - loss: 1398211585235763068928.0000\n",
      "Epoch 92/100\n",
      "3816/3816 [==============================] - 1s 224us/step - loss: 1398211595003416281088.0000\n",
      "Epoch 93/100\n",
      "3816/3816 [==============================] - 1s 208us/step - loss: 1398211550889689743360.00000s - loss:\n",
      "Epoch 94/100\n",
      "3816/3816 [==============================] - 1s 185us/step - loss: 1398211594494549688320.0000\n",
      "Epoch 95/100\n",
      "3816/3816 [==============================] - 1s 217us/step - loss: 1398211572972263047168.0000\n",
      "Epoch 96/100\n",
      "3816/3816 [==============================] - 1s 247us/step - loss: 1398211584063060049920.0000\n",
      "Epoch 97/100\n",
      "3816/3816 [==============================] - 1s 236us/step - loss: 1398211579439292612608.0000\n",
      "Epoch 98/100\n",
      "3816/3816 [==============================] - 1s 241us/step - loss: 1398211581349314691072.0000\n",
      "Epoch 99/100\n",
      "3816/3816 [==============================] - 1s 233us/step - loss: 1398211577497031802880.0000\n",
      "Epoch 100/100\n",
      "3816/3816 [==============================] - 1s 205us/step - loss: 1398211572949959835648.0000\n",
      "424/424 [==============================] - 0s 282us/step\n",
      "Epoch 1/100\n",
      "3816/3816 [==============================] - 1s 384us/step - loss: 1300896683257884835840.0000\n",
      "Epoch 2/100\n",
      "3816/3816 [==============================] - 1s 251us/step - loss: 1300896683028198981632.0000\n",
      "Epoch 3/100\n",
      "3816/3816 [==============================] - 1s 216us/step - loss: 1300896658891833606144.0000\n",
      "Epoch 4/100\n",
      "3816/3816 [==============================] - 1s 202us/step - loss: 1300896667796140982272.0000\n",
      "Epoch 5/100\n",
      "3816/3816 [==============================] - 1s 187us/step - loss: 1300896662186949345280.0000\n",
      "Epoch 6/100\n",
      "3816/3816 [==============================] - 1s 184us/step - loss: 1300896667669329608704.0000\n",
      "Epoch 7/100\n",
      "3816/3816 [==============================] - 1s 184us/step - loss: 1300896704652155813888.0000\n",
      "Epoch 8/100\n",
      "3816/3816 [==============================] - 1s 182us/step - loss: 1300896694880022036480.0000\n",
      "Epoch 9/100\n",
      "3816/3816 [==============================] - 1s 187us/step - loss: 1300896663980193611776.0000\n",
      "Epoch 10/100\n",
      "3816/3816 [==============================] - 1s 186us/step - loss: 1300896666962338512896.0000\n",
      "Epoch 11/100\n",
      "3816/3816 [==============================] - 1s 274us/step - loss: 1300896673693529800704.0000\n",
      "Epoch 12/100\n",
      "3816/3816 [==============================] - 1s 206us/step - loss: 1300896697321986719744.0000\n",
      "Epoch 13/100\n",
      "3816/3816 [==============================] - 1s 185us/step - loss: 1300896682081363951616.0000\n",
      "Epoch 14/100\n",
      "3816/3816 [==============================] - 1s 193us/step - loss: 1300896646033795186688.0000\n",
      "Epoch 15/100\n",
      "3816/3816 [==============================] - 1s 239us/step - loss: 1300896677968663805952.0000\n",
      "Epoch 16/100\n",
      "3816/3816 [==============================] - 1s 196us/step - loss: 1300896692298798858240.0000\n",
      "Epoch 17/100\n",
      "3816/3816 [==============================] - 1s 238us/step - loss: 1300896682037414461440.0000\n",
      "Epoch 18/100\n",
      "3816/3816 [==============================] - 1s 225us/step - loss: 1300896667854339309568.0000\n",
      "Epoch 19/100\n",
      "3816/3816 [==============================] - 1s 208us/step - loss: 1300896663547375779840.0000\n",
      "Epoch 20/100\n",
      "3816/3816 [==============================] - 1s 235us/step - loss: 1300896675566833369088.0000\n",
      "Epoch 21/100\n",
      "3816/3816 [==============================] - 1s 216us/step - loss: 1300896683026994954240.0000\n",
      "Epoch 22/100\n",
      "3816/3816 [==============================] - 1s 282us/step - loss: 1300896691763082166272.0000\n",
      "Epoch 23/100\n",
      "3816/3816 [==============================] - 1s 194us/step - loss: 1300896680426206658560.0000\n",
      "Epoch 24/100\n",
      "3816/3816 [==============================] - 1s 192us/step - loss: 1300896674033260822528.0000\n",
      "Epoch 25/100\n",
      "3816/3816 [==============================] - 1s 185us/step - loss: 1300896676627020775424.0000\n",
      "Epoch 26/100\n",
      "3816/3816 [==============================] - 1s 183us/step - loss: 1300896639486260674560.00000s - loss: 166\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3816/3816 [==============================] - 1s 186us/step - loss: 1300896662172033613824.0000\n",
      "Epoch 28/100\n",
      "3816/3816 [==============================] - 1s 190us/step - loss: 1300896662202843398144.0000\n",
      "Epoch 29/100\n",
      "3816/3816 [==============================] - 1s 180us/step - loss: 1300896686264596299776.0000\n",
      "Epoch 30/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1300896671638797418496.0000\n",
      "Epoch 31/100\n",
      "3816/3816 [==============================] - 1s 271us/step - loss: 1300896710020484562944.0000\n",
      "Epoch 32/100\n",
      "3816/3816 [==============================] - 1s 248us/step - loss: 1300896663337800040448.0000\n",
      "Epoch 33/100\n",
      "3816/3816 [==============================] - 1s 294us/step - loss: 1300896686148051795968.0000\n",
      "Epoch 34/100\n",
      "3816/3816 [==============================] - 1s 298us/step - loss: 1300896653137188749312.0000\n",
      "Epoch 35/100\n",
      "3816/3816 [==============================] - 1s 177us/step - loss: 1300896674114981855232.0000\n",
      "Epoch 36/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1300896662222808023040.0000\n",
      "Epoch 37/100\n",
      "3816/3816 [==============================] - 1s 203us/step - loss: 1300896670160350347264.0000\n",
      "Epoch 38/100\n",
      "3816/3816 [==============================] - 1s 180us/step - loss: 1300896662672344088576.0000\n",
      "Epoch 39/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1300896665602035810304.0000\n",
      "Epoch 40/100\n",
      "3816/3816 [==============================] - 1s 224us/step - loss: 1300896666142362042368.0000\n",
      "Epoch 41/100\n",
      "3816/3816 [==============================] - 1s 190us/step - loss: 1300896665224518565888.0000\n",
      "Epoch 42/100\n",
      "3816/3816 [==============================] - 1s 329us/step - loss: 1300896688015495921664.0000\n",
      "Epoch 43/100\n",
      "3816/3816 [==============================] - 1s 210us/step - loss: 1300896669125446205440.0000\n",
      "Epoch 44/100\n",
      "3816/3816 [==============================] - 1s 176us/step - loss: 1300896664537956876288.0000\n",
      "Epoch 45/100\n",
      "3816/3816 [==============================] - 1s 168us/step - loss: 1300896678222525628416.0000\n",
      "Epoch 46/100\n",
      "3816/3816 [==============================] - 1s 165us/step - loss: 1300896684707564486656.0000\n",
      "Epoch 47/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1300896657446431096832.0000\n",
      "Epoch 48/100\n",
      "3816/3816 [==============================] - 1s 167us/step - loss: 1300896686026339909632.0000\n",
      "Epoch 49/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1300896671173702057984.0000\n",
      "Epoch 50/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1300896670671052472320.0000\n",
      "Epoch 51/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1300896688425865052160.0000\n",
      "Epoch 52/100\n",
      "3816/3816 [==============================] - 1s 174us/step - loss: 1300896695927435165696.0000\n",
      "Epoch 53/100\n",
      "3816/3816 [==============================] - 1s 183us/step - loss: 1300896682788747739136.0000\n",
      "Epoch 54/100\n",
      "3816/3816 [==============================] - 1s 242us/step - loss: 1300896668942853472256.0000\n",
      "Epoch 55/100\n",
      "3816/3816 [==============================] - 1s 189us/step - loss: 1300896692914788237312.0000\n",
      "Epoch 56/100\n",
      "3816/3816 [==============================] - 1s 188us/step - loss: 1300896671417678692352.0000\n",
      "Epoch 57/100\n",
      "3816/3816 [==============================] - 1s 182us/step - loss: 1300896652667146469376.0000\n",
      "Epoch 58/100\n",
      "3816/3816 [==============================] - 1s 191us/step - loss: 1300896694770689114112.0000\n",
      "Epoch 59/100\n",
      "3816/3816 [==============================] - 1s 190us/step - loss: 1300896683222091431936.0000\n",
      "Epoch 60/100\n",
      "3816/3816 [==============================] - 1s 174us/step - loss: 1300896665510678626304.0000\n",
      "Epoch 61/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1300896679536244031488.0000\n",
      "Epoch 62/100\n",
      "3816/3816 [==============================] - 1s 174us/step - loss: 1300896645945430114304.0000\n",
      "Epoch 63/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1300896665164515377152.0000\n",
      "Epoch 64/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1300896676117176647680.0000\n",
      "Epoch 65/100\n",
      "3816/3816 [==============================] - 1s 181us/step - loss: 1300896665200484417536.0000\n",
      "Epoch 66/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1300896686708165967872.0000\n",
      "Epoch 67/100\n",
      "3816/3816 [==============================] - 1s 178us/step - loss: 1300896676548695293952.0000\n",
      "Epoch 68/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1300896694794835460096.0000\n",
      "Epoch 69/100\n",
      "3816/3816 [==============================] - 1s 176us/step - loss: 1300896657046651011072.0000\n",
      "Epoch 70/100\n",
      "3816/3816 [==============================] - 1s 174us/step - loss: 1300896669758814420992.0000\n",
      "Epoch 71/100\n",
      "3816/3816 [==============================] - 1s 174us/step - loss: 1300896677453258817536.0000\n",
      "Epoch 72/100\n",
      "3816/3816 [==============================] - 1s 180us/step - loss: 1300896672591745646592.0000\n",
      "Epoch 73/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1300896666312836382720.0000\n",
      "Epoch 74/100\n",
      "3816/3816 [==============================] - 1s 175us/step - loss: 1300896682512499081216.0000\n",
      "Epoch 75/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1300896676241824808960.0000\n",
      "Epoch 76/100\n",
      "3816/3816 [==============================] - 1s 171us/step - loss: 1300896680774897500160.0000\n",
      "Epoch 77/100\n",
      "3816/3816 [==============================] - 1s 175us/step - loss: 1300896682718972608512.0000\n",
      "Epoch 78/100\n",
      "3816/3816 [==============================] - 1s 179us/step - loss: 1300896667411332202496.0000\n",
      "Epoch 79/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1300896666160077209600.0000\n",
      "Epoch 80/100\n",
      "3816/3816 [==============================] - 1s 178us/step - loss: 1300896656674850078720.0000\n",
      "Epoch 81/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1300896654275539894272.0000\n",
      "Epoch 82/100\n",
      "3816/3816 [==============================] - 1s 174us/step - loss: 1300896681845865316352.0000\n",
      "Epoch 83/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1300896649045861466112.0000\n",
      "Epoch 84/100\n",
      "3816/3816 [==============================] - 1s 174us/step - loss: 1300896692473864126464.0000\n",
      "Epoch 85/100\n",
      "3816/3816 [==============================] - 1s 178us/step - loss: 1300896670875257143296.0000\n",
      "Epoch 86/100\n",
      "3816/3816 [==============================] - 1s 170us/step - loss: 1300896646339172237312.0000\n",
      "Epoch 87/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1300896653806670184448.0000\n",
      "Epoch 88/100\n",
      "3816/3816 [==============================] - 1s 177us/step - loss: 1300896647367547682816.0000\n",
      "Epoch 89/100\n",
      "3816/3816 [==============================] - 1s 169us/step - loss: 1300896669235901628416.0000\n",
      "Epoch 90/100\n",
      "3816/3816 [==============================] - 1s 175us/step - loss: 1300896670544386850816.0000\n",
      "Epoch 91/100\n",
      "3816/3816 [==============================] - 1s 173us/step - loss: 1300896681019637760000.0000\n",
      "Epoch 92/100\n",
      "3816/3816 [==============================] - 1s 190us/step - loss: 1300896665823563218944.0000\n",
      "Epoch 93/100\n",
      "3816/3816 [==============================] - 1s 198us/step - loss: 1300896656763585298432.0000\n",
      "Epoch 94/100\n",
      "3816/3816 [==============================] - 1s 179us/step - loss: 1300896667528405712896.0000\n",
      "Epoch 95/100\n",
      "3816/3816 [==============================] - 1s 203us/step - loss: 1300896682523006074880.0000\n",
      "Epoch 96/100\n",
      "3816/3816 [==============================] - 1s 317us/step - loss: 1300896651996608593920.0000\n",
      "Epoch 97/100\n",
      "3816/3816 [==============================] - 1s 263us/step - loss: 1300896653005676609536.0000\n",
      "Epoch 98/100\n",
      "3816/3816 [==============================] - 1s 176us/step - loss: 1300896685178969391104.0000\n",
      "Epoch 99/100\n",
      "3816/3816 [==============================] - 1s 176us/step - loss: 1300896675877920702464.0000\n",
      "Epoch 100/100\n",
      "3816/3816 [==============================] - 1s 172us/step - loss: 1300896665909820129280.0000\n",
      "424/424 [==============================] - 0s 275us/step\n",
      "Epoch 1/100\n",
      "3816/3816 [==============================] - 1s 262us/step - loss: 1340167838148026695680.0000\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3816/3816 [==============================] - 1s 175us/step - loss: 1340167847250374164480.0000\n",
      "Epoch 3/100\n",
      "3816/3816 [==============================] - 1s 181us/step - loss: 1340167809283471966208.0000\n",
      "Epoch 4/100\n",
      "3816/3816 [==============================] - 1s 186us/step - loss: 1340167821124484202496.0000\n",
      "Epoch 5/100\n",
      "3816/3816 [==============================] - 1s 178us/step - loss: 1340167834629798363136.0000\n",
      "Epoch 6/100\n",
      "3816/3816 [==============================] - 1s 174us/step - loss: 1340167822313432809472.0000\n",
      "Epoch 7/100\n",
      "3816/3816 [==============================] - 1s 179us/step - loss: 1340167801174949101568.0000\n",
      "Epoch 8/100\n",
      "3816/3816 [==============================] - 1s 181us/step - loss: 1340167823469655621632.0000\n",
      "Epoch 9/100\n",
      "3816/3816 [==============================] - 1s 182us/step - loss: 1340167836793191792640.0000\n",
      "Epoch 10/100\n",
      "3816/3816 [==============================] - 1s 184us/step - loss: 1340167825574757924864.0000\n",
      "Epoch 11/100\n",
      "3816/3816 [==============================] - 1s 263us/step - loss: 1340167832057187139584.0000\n",
      "Epoch 12/100\n",
      "3816/3816 [==============================] - 1s 216us/step - loss: 1340167816665440976896.0000\n",
      "Epoch 13/100\n",
      "3816/3816 [==============================] - 1s 245us/step - loss: 1340167827756570640384.0000\n",
      "Epoch 14/100\n",
      "3816/3816 [==============================] - 1s 264us/step - loss: 1340167836173092257792.0000\n",
      "Epoch 15/100\n",
      "3816/3816 [==============================] - 1s 205us/step - loss: 1340167817085441015808.0000\n",
      "Epoch 16/100\n",
      "3816/3816 [==============================] - 1s 196us/step - loss: 1340167817730324692992.0000\n",
      "Epoch 17/100\n",
      "3816/3816 [==============================] - 1s 186us/step - loss: 1340167842441346940928.0000\n",
      "Epoch 18/100\n",
      "3816/3816 [==============================] - 1s 304us/step - loss: 1340167836825662783488.0000\n",
      "Epoch 19/100\n",
      "3816/3816 [==============================] - 1s 214us/step - loss: 1340167854627822239744.0000\n",
      "Epoch 20/100\n",
      "3816/3816 [==============================] - 1s 186us/step - loss: 1340167833541444632576.0000\n",
      "Epoch 21/100\n",
      "3560/3816 [==========================>...] - ETA: 0s - loss: 1248055104930521808896.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f6881fc42508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wider: %.2f (%.2f) MSE\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1137\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \"\"\"\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \"\"\"\n\u001b[1;32m    369\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \"\"\"\n\u001b[1;32m    369\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 300\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    301\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3489\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3490\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3492\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3508\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allow_tensor and allow_operation can't both be False.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0mtemp_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtemp_obj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m       \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m   \u001b[0mconv_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_as_graph_element\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconv_fn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconv_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed=42\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
